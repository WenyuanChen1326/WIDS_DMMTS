{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Aim 3</h1>\n",
    "<h3>WIDS 2024 Challenge ++</h3>\n",
    "<h3>BMI 212 - Team DMMTS</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Manoj Maddali, MD</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, RocCurveDisplay, auc, mean_squared_error, accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Load the data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV dataset\n",
    "nonimpute_raw_df = pd.read_csv('../Data/train_test_added_climate_data.csv')\n",
    "impute_raw_df = pd.read_csv('../Data/train_test_added_climate_data_imputed.csv')\n",
    "\n",
    "# Rename feature columns for better readability\n",
    "columns_dict = {'bmi': 'patient_bmi',\n",
    "                   'region': 'patient_region',\n",
    "                   'division': 'patient_division',\n",
    "                   'side': 'patient_tumor_side',\n",
    "                   'quadrant': 'patient_tumor_quadrant',\n",
    "                   'metastatic_organ': 'patient_metastatic_organ',\n",
    "                   'cleaned_metastatic_first_treatment': 'patient_metastatic_first_treatment',\n",
    "                   'cleaned_metastatic_first_treatment_type': 'patient_metastatic_first_treatment_type',\n",
    "                   'population': 'population_size',\n",
    "                   'density': 'population_density',\n",
    "                   'age_median': 'population_age_median',\n",
    "                   'female': 'population_female_perc',\n",
    "                   'married': 'population_married_perc',\n",
    "                   'divorced': 'population_divorced_perc',\n",
    "                   'never_married': 'population_never_married_perc',\n",
    "                   'widowed': 'population_widowed_perc',\n",
    "                   'family_size': 'population_family_size',\n",
    "                   'family_dual_income': 'population_family_dual_income_perc',\n",
    "                   'income_individual_median': 'population_income_individual_median',\n",
    "                   'income_household_median': 'population_income_household_median',\n",
    "                   'home_ownership': 'population_home_ownership_perc',\n",
    "                   'home_value': 'population_home_value',\n",
    "                   'rent_median': 'population_rent_median',\n",
    "                   'rent_burden': 'population_rent_burden_perc',\n",
    "                   'education_less_highschool': 'population_education_less_highschool_perc',\n",
    "                   'education_highschool': 'population_education_highschool_perc',\n",
    "                   'education_some_college': 'population_education_some_college_perc',\n",
    "                   'education_bachelors': 'population_education_bachelors_perc',\n",
    "                   'education_graduate': 'population_education_graduate_perc',\n",
    "                   'education_college_or_above': 'population_education_college_or_above_perc',\n",
    "                   'education_stem_degree': 'population_education_stem_degree_perc',\n",
    "                   'unemployment_rate': 'population_unemployment_rate',\n",
    "                   'self_employed': 'population_self_employed_perc',\n",
    "                   'farmer': 'population_farmer_perc',\n",
    "                   'race_white': 'population_race_white_perc',\n",
    "                   'race_black': 'population_race_black_perc',\n",
    "                   'race_asian': 'population_race_asian_perc',\n",
    "                   'race_native': 'population_race_native_american_perc',\n",
    "                   'race_pacific': 'population_race_pacific_islander_perc',\n",
    "                   'race_other': 'population_race_other_perc',\n",
    "                   'race_multiple': 'population_race_multiple_perc',\n",
    "                   'hispanic': 'population_hispanic_perc',\n",
    "                   'disabled': 'population_disabled_perc',\n",
    "                   'poverty': 'population_poverty_perc',\n",
    "                   'limited_english': 'population_limited_english_perc',\n",
    "                   'commute_time': 'population_commute_time',\n",
    "                   'health_uninsured': 'population_health_uninsured_perc',\n",
    "                   'veteran': 'population_veteran_perc',\n",
    "                   'climate_ozone': 'annual_ozone_conc',\n",
    "                   'climate_pm25': 'annual_fine_particulate_matter_conc',\n",
    "                   'climate_n02': 'annual_nitrogen_dioxide_conc',\n",
    "                   'Ozone': 'annual_ozone_conc',\n",
    "                   'PM25': 'annual_fine_particulate_matter_conc',\n",
    "                   'N02': 'annual_nitrogen_dioxide_conc'}\n",
    "\n",
    "nonimpute_raw_df.rename(columns=columns_dict, inplace=True)\n",
    "impute_raw_df.rename(columns=columns_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Select the features to use</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['patient_race', 'payer_type', 'patient_state', 'patient_age', 'patient_gender', 'patient_bmi',\n",
    "            'patient_region', 'patient_division', 'patient_tumor_side', 'patient_tumor_quadrant',\n",
    "            'patient_metastatic_organ', 'patient_metastatic_first_treatment', 'patient_metastatic_first_treatment_type',\n",
    "            'population_size', 'population_density', 'population_age_median', 'population_female_perc',\n",
    "            'population_married_perc', 'population_divorced_perc', 'population_never_married_perc',\n",
    "            'population_widowed_perc', 'population_family_size', 'population_family_dual_income_perc',\n",
    "            'population_income_individual_median', 'population_income_household_median', 'population_home_ownership_perc',\n",
    "            'population_home_value', 'population_rent_median', 'population_rent_burden_perc',\n",
    "            'population_education_less_highschool_perc', 'population_education_highschool_perc',\n",
    "            'population_education_some_college_perc', 'population_education_bachelors_perc',\n",
    "            'population_education_graduate_perc', 'population_education_college_or_above_perc',\n",
    "            'population_education_stem_degree_perc', 'population_unemployment_rate', 'population_self_employed_perc',\n",
    "            'population_farmer_perc', 'population_race_white_perc', 'population_race_black_perc',\n",
    "            'population_race_asian_perc', 'population_race_native_american_perc', 'population_race_pacific_islander_perc',\n",
    "            'population_race_other_perc', 'population_race_multiple_perc', 'population_hispanic_perc',\n",
    "            'population_disabled_perc', 'population_poverty_perc', 'population_limited_english_perc',\n",
    "            'population_commute_time', 'population_health_uninsured_perc', 'population_veteran_perc', 'annual_nitrogen_dioxide_conc',\n",
    "            'annual_fine_particulate_matter_conc', 'annual_ozone_conc']\n",
    "\n",
    "# Select only rows where allocated_set is train\n",
    "nonimpute_train_df = nonimpute_raw_df[nonimpute_raw_df['allocated_set'] == 'train']\n",
    "impute_train_df = impute_raw_df[impute_raw_df['allocated_set'] == 'train']\n",
    "\n",
    "# Select the features to use\n",
    "nonimpute_df = nonimpute_train_df[features]\n",
    "impute_df = impute_train_df[features]\n",
    "\n",
    "# Extract labels for time to treatment \n",
    "labels_df = nonimpute_train_df[['treatment_pd']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Define categorical variables</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['patient_race', 'payer_type', 'patient_state', 'patient_gender', 'patient_region', 'patient_division', 'patient_tumor_side', 'patient_tumor_quadrant', 'patient_metastatic_organ', 'patient_metastatic_first_treatment', 'patient_metastatic_first_treatment_type']\n"
     ]
    }
   ],
   "source": [
    "# Convert object features to categorical\n",
    "for col in nonimpute_df.select_dtypes(include='object').columns:\n",
    "    nonimpute_df[col] = nonimpute_df[col].astype('category')\n",
    "    impute_df[col] = impute_df[col].astype('category')\n",
    "\n",
    "# List of categorical features\n",
    "categorical_features = list(nonimpute_df.select_dtypes(include='category').columns)\n",
    "print(categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporarily convert categorical features to distinct numerical codes, keeping missing/NaN values\n",
    "temp_nonimpute_df = nonimpute_df.copy()\n",
    "temp_impute_df = impute_df.copy()\n",
    "\n",
    "for cat_feat in categorical_features:\n",
    "    temp_nonimpute_df[cat_feat] = temp_nonimpute_df[cat_feat].cat.codes\n",
    "    temp_impute_df[cat_feat] = temp_impute_df[cat_feat].cat.codes\n",
    "\n",
    "    temp_nonimpute_df.loc[temp_nonimpute_df[cat_feat] == -1] = np.NaN\n",
    "    temp_impute_df.loc[temp_impute_df[cat_feat] == -1] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-imputed Low-variance features:  {'patient_gender', 'population_family_size', 'patient_metastatic_first_treatment_type'}\n",
      "Imputed Low-variance features:  {'patient_gender', 'population_family_size', 'patient_metastatic_first_treatment_type'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Remove low-var features from temp df (will drop removed cols from original df)\n",
    "low_var_filter_nonimpute = VarianceThreshold(threshold=(.9 * (1 - .9)))\n",
    "filtered_features_nonimpute = low_var_filter_nonimpute.fit_transform(temp_nonimpute_df)\n",
    "filtered_feature_names_nonimpute = low_var_filter_nonimpute.get_feature_names_out(input_features=features)\n",
    "print(\"Non-imputed Low-variance features: \", set(features) - set(filtered_feature_names_nonimpute))\n",
    "\n",
    "low_var_filter_impute = VarianceThreshold(threshold=(.9 * (1 - .9)))\n",
    "filtered_features_impute = low_var_filter_impute.fit_transform(temp_impute_df)\n",
    "filtered_feature_names_impute = low_var_filter_impute.get_feature_names_out(input_features=features)\n",
    "print(\"Imputed Low-variance features: \", set(features) - set(filtered_feature_names_impute))\n",
    "\n",
    "nonimpute_df_filtered = nonimpute_df[filtered_feature_names_nonimpute].copy()\n",
    "impute_df_filtered = impute_df[filtered_feature_names_impute].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorize label to 30/60/90 day treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename dfs of features and target\n",
    "X_nonimpute = nonimpute_df_filtered\n",
    "X_impute = impute_df_filtered\n",
    "y = labels_df\n",
    "\n",
    "y_30 = y['treatment_pd'].apply(lambda x: 1 if x <= 30 else 0)\n",
    "\n",
    "y_60 = y['treatment_pd'].apply(lambda x: 1 if x <= 60 else 0)\n",
    "\n",
    "y_90 = y['treatment_pd'].apply(lambda x: 1 if x <= 90 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into train/test 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    17714\n",
      "1     4425\n",
      "Name: treatment_pd, dtype: int64\n",
      "0    4429\n",
      "1    1106\n",
      "Name: treatment_pd, dtype: int64\n",
      "0    12685\n",
      "1     9454\n",
      "Name: treatment_pd, dtype: int64\n",
      "0    3171\n",
      "1    2364\n",
      "Name: treatment_pd, dtype: int64\n",
      "1    13549\n",
      "0     8590\n",
      "Name: treatment_pd, dtype: int64\n",
      "1    3387\n",
      "0    2148\n",
      "Name: treatment_pd, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train/test split (80/20) - preserve class counts between splits\n",
    "X_train_nonimpute_30, X_test_nonimpute_30, y_train_30, y_test_30 = train_test_split(X_nonimpute, y_30, test_size=0.2, random_state=123, stratify=y_30)\n",
    "X_train_impute_30, X_test_impute_30, y_train_30, y_test_30 = train_test_split(X_impute, y_30, test_size=0.2, random_state=123, stratify=y_30)\n",
    "print(y_train_30.value_counts())\n",
    "print(y_test_30.value_counts())\n",
    "\n",
    "X_train_nonimpute_60, X_test_nonimpute_60, y_train_60, y_test_60 = train_test_split(X_nonimpute, y_60, test_size=0.2, random_state=123, stratify=y_60)\n",
    "X_train_impute_60, X_test_impute_60, y_train_60, y_test_60 = train_test_split(X_impute, y_60, test_size=0.2, random_state=123, stratify=y_60)\n",
    "print(y_train_60.value_counts())\n",
    "print(y_test_60.value_counts())\n",
    "\n",
    "X_train_nonimpute_90, X_test_nonimpute_90, y_train_90, y_test_90 = train_test_split(X_nonimpute, y_90, test_size=0.2, random_state=123, stratify=y_90)\n",
    "X_train_impute_90, X_test_impute_90, y_train_90, y_test_90 = train_test_split(X_impute, y_90, test_size=0.2, random_state=123, stratify=y_90)\n",
    "print(y_train_90.value_counts())\n",
    "print(y_test_90.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputed - LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Imputed 30-day classification</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=LGBMClassifier(),\n",
       "             param_grid={&#x27;boosting_type&#x27;: [&#x27;dart&#x27;], &#x27;colsample_bytree&#x27;: [0.9],\n",
       "                         &#x27;is_unbalance&#x27;: [True], &#x27;learning_rate&#x27;: [0.05, 0.1],\n",
       "                         &#x27;metric&#x27;: [&#x27;auc&#x27;], &#x27;n_estimators&#x27;: [50, 100],\n",
       "                         &#x27;num_leaves&#x27;: [31, 63], &#x27;objective&#x27;: [&#x27;binary&#x27;],\n",
       "                         &#x27;subsample&#x27;: [0.9], &#x27;subsample_freq&#x27;: [10],\n",
       "                         &#x27;verbose&#x27;: [-1]},\n",
       "             scoring=&#x27;roc_auc&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=LGBMClassifier(),\n",
       "             param_grid={&#x27;boosting_type&#x27;: [&#x27;dart&#x27;], &#x27;colsample_bytree&#x27;: [0.9],\n",
       "                         &#x27;is_unbalance&#x27;: [True], &#x27;learning_rate&#x27;: [0.05, 0.1],\n",
       "                         &#x27;metric&#x27;: [&#x27;auc&#x27;], &#x27;n_estimators&#x27;: [50, 100],\n",
       "                         &#x27;num_leaves&#x27;: [31, 63], &#x27;objective&#x27;: [&#x27;binary&#x27;],\n",
       "                         &#x27;subsample&#x27;: [0.9], &#x27;subsample_freq&#x27;: [10],\n",
       "                         &#x27;verbose&#x27;: [-1]},\n",
       "             scoring=&#x27;roc_auc&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LGBMClassifier(),\n",
       "             param_grid={'boosting_type': ['dart'], 'colsample_bytree': [0.9],\n",
       "                         'is_unbalance': [True], 'learning_rate': [0.05, 0.1],\n",
       "                         'metric': ['auc'], 'n_estimators': [50, 100],\n",
       "                         'num_leaves': [31, 63], 'objective': ['binary'],\n",
       "                         'subsample': [0.9], 'subsample_freq': [10],\n",
       "                         'verbose': [-1]},\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the LightGBM dataset\n",
    "train_data_30 = lgb.Dataset(X_train_impute_30, label=y_train_30, feature_name='auto', categorical_feature=categorical_features)\n",
    "test_data_30 = lgb.Dataset(X_test_impute_30, label=y_test_30, feature_name='auto', categorical_feature=categorical_features)\n",
    "\n",
    "# Define the hyperparameters for a classification model\n",
    "params = {\n",
    "    'objective': ['binary'],\n",
    "    'metric': ['auc'], \n",
    "    'is_unbalance': [True],\n",
    "    'boosting_type': ['dart'], \n",
    "    'n_estimators': [50, 100],\n",
    "    'num_leaves': [31, 63],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'colsample_bytree': [0.9],\n",
    "    'subsample': [0.9],\n",
    "    'subsample_freq': [10],\n",
    "    'verbose': [-1],\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "model_impute_30 = lgb.LGBMClassifier()\n",
    "\n",
    "# Create the grid search\n",
    "grid_impute_30 = GridSearchCV(model_impute_30, params, cv=10, scoring='roc_auc')\n",
    "\n",
    "# Fit the model to the data\n",
    "grid_impute_30.fit(X_train_impute_30, y_train_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'boosting_type': 'dart', 'colsample_bytree': 0.9, 'is_unbalance': True, 'learning_rate': 0.05, 'metric': 'auc', 'n_estimators': 50, 'num_leaves': 31, 'objective': 'binary', 'subsample': 0.9, 'subsample_freq': 10, 'verbose': -1}\n",
      "Insample AUC: 0.7001098101655292\n",
      "AUC: 0.7138134243439896\n"
     ]
    }
   ],
   "source": [
    "# Print best parameters\n",
    "print('Best parameters:', grid_impute_30.best_params_)\n",
    "\n",
    "# Print best in-sample score\n",
    "print('Insample AUC:', grid_impute_30.best_score_)\n",
    "\n",
    "# Test the model\n",
    "y_test_pred_impute_lgb_30 = grid_impute_30.predict_proba(X_test_impute_30)[:,1]\n",
    "\n",
    "# Calculate AUC\n",
    "fpr_30, tpr_30, thresholds = roc_curve(y_test_30, y_test_pred_impute_lgb_30)\n",
    "\n",
    "# Roc AUC\n",
    "roc_auc_30 = auc(fpr_30, tpr_30)\n",
    "\n",
    "# Print AUC\n",
    "print('AUC:', roc_auc_30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fairness - Equalized odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equalized odds by race:               true_positive_rate  false_positive_rate\n",
      "patient_race                                         \n",
      "Asian                   0.533333             0.207207\n",
      "Black                   0.579545             0.295905\n",
      "Hispanic                0.523364             0.285714\n",
      "Other                   0.602410             0.300787\n",
      "White                   0.630719             0.303439\n",
      "Equalized odds ratio by race: 0.6828622022309253\n",
      "Equalized odds difference by race: 0.10735446826705763\n"
     ]
    }
   ],
   "source": [
    "from fairlearn.metrics import equalized_odds_ratio, equalized_odds_difference, MetricFrame, true_positive_rate, false_positive_rate\n",
    "\n",
    "equalized_odds_metrics = {\n",
    "    'true_positive_rate': true_positive_rate,\n",
    "    'false_positive_rate': false_positive_rate}\n",
    "\n",
    "## By Race\n",
    "equalized_odds_race = MetricFrame(metrics=equalized_odds_metrics,\n",
    "                                  y_true=y_test_30,\n",
    "                                  y_pred=(y_test_pred_impute_lgb_30 > 0.5).astype(int),\n",
    "                                  sensitive_features=X_test_impute_30['patient_race'])\n",
    "\n",
    "print('Equalized odds by race:', equalized_odds_race.by_group)\n",
    "\n",
    "print('Equalized odds ratio by race:', equalized_odds_ratio(y_true=y_test_30,\n",
    "                                                            y_pred=(y_test_pred_impute_lgb_30 > 0.5).astype(int),\n",
    "                                                            sensitive_features = X_test_impute_30['patient_race']))\n",
    "\n",
    "print('Equalized odds difference by race:', equalized_odds_difference(y_true=y_test_30,\n",
    "                                                                     y_pred=(y_test_pred_impute_lgb_30 > 0.5).astype(int),\n",
    "                                                                     sensitive_features = X_test_impute_30['patient_race']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before/After Mitigation with Reductions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.reductions import ExponentiatedGradient, EqualizedOdds\n",
    "\n",
    "mitigator = ExponentiatedGradient(grid_impute_30.best_estimator_, constraints=EqualizedOdds())\n",
    "\n",
    "mitigator.fit(X_train_impute_30, y_train_30, sensitive_features=X_train_impute_30['patient_race'])\n",
    "\n",
    "y_test_pred_impute_lgb_30_reduction = mitigator.predict(X_test_impute_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equalized odds by race:               true_positive_rate  false_positive_rate\n",
      "patient_race                                         \n",
      "Asian                   0.511111             0.220721\n",
      "Black                   0.448864             0.244386\n",
      "Hispanic                0.420561             0.264479\n",
      "Other                   0.493976             0.266142\n",
      "White                   0.486928             0.224205\n",
      "Equalized odds ratio by race: 0.8228362454286876\n",
      "Equalized odds difference by race: 0.09055036344755968\n"
     ]
    }
   ],
   "source": [
    "from fairlearn.metrics import equalized_odds_ratio, equalized_odds_difference, MetricFrame, true_positive_rate, false_positive_rate\n",
    "\n",
    "equalized_odds_metrics = {\n",
    "    'true_positive_rate': true_positive_rate,\n",
    "    'false_positive_rate': false_positive_rate}\n",
    "\n",
    "## By Race\n",
    "equalized_odds_race = MetricFrame(metrics=equalized_odds_metrics,\n",
    "                                  y_true=y_test_30,\n",
    "                                  y_pred=(y_test_pred_impute_lgb_30_reduction > 0.5).astype(int),\n",
    "                                  sensitive_features=X_test_impute_30['patient_race'])\n",
    "\n",
    "print('Equalized odds by race:', equalized_odds_race.by_group)\n",
    "\n",
    "print('Equalized odds ratio by race:', equalized_odds_ratio(y_true=y_test_30,\n",
    "                                                            y_pred=(y_test_pred_impute_lgb_30_reduction > 0.5).astype(int),\n",
    "                                                            sensitive_features = X_test_impute_30['patient_race']))\n",
    "\n",
    "print('Equalized odds difference by race:', equalized_odds_difference(y_true=y_test_30,\n",
    "                                                                     y_pred=(y_test_pred_impute_lgb_30_reduction > 0.5).astype(int),\n",
    "                                                                     sensitive_features = X_test_impute_30['patient_race']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bmi212",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
